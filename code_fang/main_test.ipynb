{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import scipy\n",
    "# import pandas\n",
    "import torch\n",
    "import utils\n",
    "from utils import generate_state_space_Matern_23\n",
    "from scipy import linalg\n",
    "from utils import build_id_key_table\n",
    "from model_Bayes_diffusion import Bayes_diffu_tensor\n",
    "import tqdm\n",
    "\n",
    "data_file = '../processed_data/beijing_15k.npy'\n",
    "full_data = np.load(data_file, allow_pickle=True).item()\n",
    "\n",
    "fold=0\n",
    "\n",
    "# here should add one more data-loader class\n",
    "data_dict = full_data['data'][fold]\n",
    "data_dict['ndims'] = full_data['ndims']\n",
    "data_dict['num_node'] = full_data['num_node']\n",
    "\n",
    "data_dict['time_id_table'] = full_data['time_id_table']\n",
    "data_dict['time_uni'] = full_data['time_uni']\n",
    "\n",
    "\n",
    "hyper_dict={}\n",
    "\n",
    "hyper_dict['epoch'] = 2\n",
    "hyper_dict['ls'] = 0.1\n",
    "hyper_dict['var'] = 0.1\n",
    "hyper_dict['device'] = torch.device(\"cpu\")\n",
    "hyper_dict['R_U'] = 2 # dim of each node embedding\n",
    "hyper_dict['c'] = 0.1 # diffusion rate\n",
    "hyper_dict['a0']=1.0\n",
    "hyper_dict['b0']=1.0\n",
    "\n",
    "\n",
    "F,P_inf = utils.generate_state_space_Matern_23(data_dict,hyper_dict)\n",
    "\n",
    "data_dict['F'] = F\n",
    "data_dict['P_inf'] = P_inf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [3,2,1]\n",
    "ind_tr = data_dict[\"tr_ind\"]\n",
    "U= torch.rand(20,5,5,20)\n",
    "U[a,:,:,b].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "torch.diag_embed(torch.rand(20,5),dim1=1).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "np.stack([a for i in range(5)],axis=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2],\n",
       "       [3, 3, 3, 3, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "N_T = len(data_dict['time_uni'])\n",
    "\n",
    "model = Bayes_diffu_tensor(data_dict,hyper_dict)\n",
    "test_rmse = model.model_test()\n",
    "print('init state: test_rmse: %.4f '%(test_rmse))\n",
    "\n",
    "EPOCH = 1\n",
    "for epoch in tqdm.tqdm(range(EPOCH)):\n",
    "    # forward\n",
    "    for T in range(N_T):\n",
    "        model.msg_update_U_llk_del(T)\n",
    "        model.msg_update_U_llk(T)\n",
    "\n",
    "        \n",
    "\n",
    "        if T<N_T-1:\n",
    "            model.msg_update_U_trans_del(T,mode='forward')\n",
    "            # model.msg_update_U_trans_del(T,mode='backward')\n",
    "            model.msg_update_U_trans_vec(T,mode='forward')\n",
    "            # model.msg_update_U_trans(T,mode='forward')\n",
    "\n",
    "        # assert utils.nan_check_1(model,T) is True\n",
    "        # assert utils.neg_check_v(model,T) is True\n",
    "    model.msg_update_U_trans_del(N_T-1,mode='backward')\n",
    "    \n",
    "    model.post_update_U()\n",
    "    test_rmse = model.model_test()\n",
    "    print('it: %d, test_rmse: %.4f '%(epoch,test_rmse))\n",
    "    \n",
    "    # backward \n",
    "    for T in reversed(range(N_T-1)):\n",
    "        \n",
    "        # model.msg_update_U_trans(T,mode='backward')\n",
    "        model.msg_update_U_trans_vec(T,mode='backward')\n",
    "\n",
    "        model.msg_update_U_llk_del(T)\n",
    "        model.msg_update_U_llk(T)\n",
    "\n",
    "        model.msg_update_U_trans_del(T,mode='backward')\n",
    "        utils.nan_check_1(model,T)\n",
    "        \n",
    "    model.post_update_U()\n",
    "    test_rmse = model.model_test()\n",
    "    print('it: %d, test_rmse: %.4f '%(epoch,test_rmse))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'DAMPING'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m N_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_uni\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBayes_diffu_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhyper_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m test_rmse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel_test()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit state: test_rmse: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(test_rmse))\n",
      "File \u001b[0;32m~/fang/diffusion_tensor/code_fang/model_Bayes_diffusion.py:20\u001b[0m, in \u001b[0;36mBayes_diffu_tensor.__init__\u001b[0;34m(self, data_dict, hyper_dict)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR_U \u001b[38;5;241m=\u001b[39m hyper_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR_U\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# rank of latent factor of embedding\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m hyper_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDAMPING \u001b[38;5;241m=\u001b[39m \u001b[43mhyper_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDAMPING\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma0 \u001b[38;5;241m=\u001b[39m hyper_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb0 \u001b[38;5;241m=\u001b[39m hyper_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DAMPING'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "T"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "time_gap = model.time_uni[T+1] - model.time_uni[T]\n",
    "A_T_block = torch.block_diag(*([torch.matrix_exp(model.F * time_gap)]*model.R_U))\n",
    "P_inf_block = torch.block_diag(*([model.P_inf]*model.R_U))\n",
    "Q_T_block = P_inf_block - P_inf_block @ A_T_block @ P_inf_block.T\n",
    "\n",
    "msg_m_l = model.msg_U_f_m_del[:,:,T].T.reshape(-1)\n",
    "msg_v_l = model.msg_U_f_v_del[:,:,T].T.reshape(-1)\n",
    "    \n",
    "# msg from the right (from U_{T+1})\n",
    "msg_m_r = model.msg_U_b_m_del[:,:,T+1].T.reshape(-1)\n",
    "msg_v_r = model.msg_U_b_v_del[:,:,T+1].T.reshape(-1)\n",
    "\n",
    "msg_m_r.requires_grad=True \n",
    "msg_v_r.requires_grad=True \n",
    "target_m = msg_m_r\n",
    "target_v = msg_v_r\n",
    "\n",
    "mu = (A_T_block @ msg_m_l.view(-1,1)).squeeze() # num_node * 1\n",
    "sigma = torch.diag(msg_v_r) + Q_T_block + A_T_block @ torch.diag(msg_v_l) @ A_T_block.T\n",
    "sample = msg_m_r\n",
    "\n",
    "# print(sample)\n",
    "\n",
    "# compute log-Z\n",
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(mu, sigma)\n",
    "log_Z_trans = dist.log_prob(sample)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "print(model.msg_U_f_m[:30,:,46].max())\n",
    "print(model.msg_U_f_m[:30,:,47].max())\n",
    "print(model.msg_U_llk_m_del[:,:,38].abs().max())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.6097, dtype=torch.float64)\n",
      "tensor(27.7729, dtype=torch.float64)\n",
      "tensor(2.0244, dtype=torch.float64)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "T = 46\n",
    "eind_T = model.time_data_table_tr[T] # id of observed entries at this time-stamp\n",
    "N_T = len(eind_T) \n",
    "ind_T = model.ind_tr[eind_T]\n",
    "y_T = model.y_tr[eind_T].squeeze()\n",
    "\n",
    "uid_table, _ = build_id_key_table( model.nmod,ind_T) # get the id of associated nodes\n",
    "uid_list = []\n",
    "for mode in range( model.nmod):\n",
    "    uid_list_mode = [item + sum( model.ndims[:mode]) for item in uid_table[mode]]\n",
    "    uid_list = uid_list + uid_list_mode\n",
    "uid = np.array(uid_list).astype(np.int64)\n",
    "\n",
    "# self.uid_table_T = uid_table\n",
    "# self.ind_T = ind_T\n",
    "\n",
    "U_llk_del_T = torch.cat([ model.msg_U_llk_m_del[:,:,T], model.msg_U_llk_v_del[:,:,T]]) # concat the m and v \n",
    "U_llk_del_T.requires_grad=True \n",
    "\n",
    "U_llk_del_T_m,U_llk_del_T_v =  model.arrange_U_llk(U_llk_del_T) # arrange U as mode-wise\n",
    "\n",
    "E_z_del, E_z_2_del =  model.moment_product_U_del(ind_T,U_llk_del_T_m,U_llk_del_T_v) # first and second moment of CP-pred\n",
    "\n",
    "model.msg_update_tau_del(T)\n",
    "E_tau_del =  model.msg_tau_a_del_T[T]/ model.msg_tau_b_del_T[T]\n",
    "\n",
    "log_Z = 0.5*N_T*torch.log(E_tau_del/(2*np.pi)) \\\n",
    "    -  0.5*E_tau_del* ( (y_T*y_T).sum() - 2* (y_T*E_z_del).sum() + E_z_2_del.sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "U_llk_del_T_m"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([[-2.0438, -1.8718],\n",
       "         [ 0.3564,  0.5065],\n",
       "         [-0.3009, -0.0341],\n",
       "         [-3.6314, -1.0142],\n",
       "         [-1.6843, -1.7258],\n",
       "         [-2.4998, -2.8594],\n",
       "         [-1.6391, -1.1571],\n",
       "         [-2.1869, -1.7163],\n",
       "         [-1.5967, -1.6505],\n",
       "         [ 0.5131,  0.5052],\n",
       "         [-1.1689, -1.2142],\n",
       "         [-3.4670, -3.5964]], dtype=torch.float64, grad_fn=<SliceBackward>),\n",
       " tensor([[ 0.2203,  0.2832],\n",
       "         [-2.0660, -2.6955],\n",
       "         [-0.8595, -1.1216],\n",
       "         [-0.9167, -1.0435],\n",
       "         [ 0.3965,  0.3202],\n",
       "         [-0.9552, -1.1956]], dtype=torch.float64, grad_fn=<SliceBackward>),\n",
       " tensor([[-2.0017, -1.9888],\n",
       "         [-3.8004, -3.5413],\n",
       "         [-3.0486, -2.9562],\n",
       "         [-3.8260, -3.1128],\n",
       "         [-6.6637, -6.4537],\n",
       "         [-3.5730, -3.3011],\n",
       "         [-6.0867, -2.8219],\n",
       "         [-2.7000, -2.6690],\n",
       "         [-5.3401, -5.0419],\n",
       "         [-3.5458, -3.2852],\n",
       "         [-4.4689, -4.2325],\n",
       "         [-5.2201, -5.2612]], dtype=torch.float64, grad_fn=<SliceBackward>)]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "y_T"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.4085, -0.5081, -0.3995, -0.2412], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "model.msg_U_f_m[:30,:,44].max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-0.0139, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "model.msg_U_b_m[:30,:,45].max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.9733, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2b9b245c32fdd00062c065bea1c6c406b1fa841caa084ac758573a37ef3ce19"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('pytorch_1.10.1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}