{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import scipy\n",
                "import pandas\n",
                "import torch\n",
                "import utils\n",
                "from utils import generate_state_space_Matern_23\n",
                "from scipy import linalg\n",
                "from utils import build_id_key_table\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_file = '../processed_data/beijing_15k.npy'\n",
                "data_dict = np.load(data_file, allow_pickle=True).item()\n",
                "\n",
                "fold=0\n",
                "\n",
                "# here should add one more data-loader class\n",
                "\n",
                "\n",
                "\n",
                "hyper_dict={}\n",
                "hyper_dict['ls'] = 0.5\n",
                "hyper_dict['var'] = 0.1\n",
                "hyper_dict['device'] = torch.device(\"cpu\")\n",
                "hyper_dict['R_U'] = 5 # dim of each node embedding\n",
                "hyper_dict['c'] = 1.0 # diffusion rate\n",
                "\n",
                "F,P_inf = utils.generate_state_space_Matern_23(data_dict,hyper_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data process:\n",
                "\n",
                "class Bayes_diffu_tensor():\n",
                "    def __init__(self,data_dict,hyper_dict):\n",
                "\n",
                "\n",
                "        # hyper-paras\n",
                "        self.epoch = hyper_dict['epoch'] # passing epoch\n",
                "        self.R_U = hyper_dict['R_U'] # rank of latent factor of embedding\n",
                "        self.device = hyper_dict['device']\n",
                "        \n",
                "        self.a0 = hyper_dict['a0']\n",
                "        self.b0 = hyper_dict['b0']\n",
                "        \n",
                "        \n",
                "\n",
                "        # data-dependent paras\n",
                "        self.data_dict = data_dict\n",
                "        \n",
                "        self.ind_tr = data_dict['ind_tr']\n",
                "        self.y_tr = data_dict['y_tr'].to(self.device) # N*1\n",
                "        self.N = len(data_dict['y_tr'])\n",
                "        self.ndims = data_dict['ndims']\n",
                "        self.num_nodes = sum(self.ndims)\n",
                "        \n",
                "        self.train_time_ind =data_dict['tr_T_disct'] # N*1\n",
                "        self.test_time_ind = data_dict['te_T_disct'] # N*1\n",
                "        \n",
                "        self.time_uni = data_dict['time_uni'] # N_time*1\n",
                "        self.N_time = data_dict['N_time']  \n",
                "        \n",
                "        self.time_id_table = data_dict['time_id_table']\n",
                "        self.F = data_dict['F'].to(self.device) # transition matrix\n",
                "        self.P_inf = data_dict['P_inf'].to(self.device) # stationary covar\n",
                "        \n",
                "    \n",
                "            \n",
                "        # init the message factor of llk term (U_llk, tau)\n",
                "        # and transition term (U_f: U_forard, U_b: U_backward)\n",
                "        \n",
                "        # actually, it's the massage from llk-factor -> variabel U\n",
                "        # for here, we arrange the U-msg in mode-node way for efficient indexing in LLK\n",
                "        self.msg_U_llk_m = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_U_llk_v = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_tau_a = torch.ones(self.N_time,1).to(self.device)\n",
                "        self.msg_tau_b = torch.ones(self.N_time,1).to(self.device)\n",
                "        \n",
                "        # actually, it's the massage from transition-factor -> variabel U\n",
                "        # for here, we arrange the U-msg in concat-all way for efficient computing in transition\n",
                "        self.msg_U_f_m = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_f_v = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        \n",
                "        self.msg_U_b_m = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_b_v = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time \n",
                "\n",
                "\n",
                "    \n",
                "        # init the calibrating factors / q_del in draft\n",
                "        \n",
                "        # actually, it's the massage from variabel U -> llk-factor\n",
                "        self.msg_U_llk_m_del = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_U_llk_v_del = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        # as the computing of msg_tau_del is trival, we don't assign extra varb gor it  \n",
                "        \n",
                "        # actually, it's the massage from variabel U -> trans-factor\n",
                "        self.msg_U_f_m_del = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_f_v_del = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        \n",
                "        self.msg_U_b_m_del = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_b_v_del = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time \n",
                "        \n",
                "    \n",
                "        # init the post. U\n",
                "        \n",
                "        self.post_U_m = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.post_U_v = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        # uid-data table \n",
                "        self.uid_table, self.data_table = build_id_key_table(self.nmod,self.ind_tr) \n",
                "        \n",
                "\n",
                "def msg_update_U_llk(self,T):\n",
                "    pass\n",
                "    \n",
                "def msg_update_U_trans(self,T,mode='forward'):\n",
                "    pass\n",
                "\n",
                "def msg_update_tau(self,T):\n",
                "    pass\n",
                "\n",
                "def msg_update_U_llk_del(self,T):\n",
                "    pass\n",
                "    \n",
                "def msg_update_U_trans_del(self,T):\n",
                "    pass\n",
                "\n",
                "def post_update_U(self,T):\n",
                "    pass\n",
                "    \n",
                "def post_update_tau(self):\n",
                "    pass\n",
                "    \n",
                "        \n",
                "        \n",
                "        \n",
                "        \n",
                "        \n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "F,P_inf = utils.generate_state_space_Matern_23(data_dict,hyper_dict,fold)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([5, 3, 3])"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = [torch.rand(3,3,3),torch.rand(2,3,3)]\n",
                "torch.cat(a,0).shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[[ 0.2385,  0.8594, 14.5998],\n",
                            "         [ 0.8539,  0.3681,  1.2468],\n",
                            "         [ 3.4039,  0.8496,  2.9541]],\n",
                            "\n",
                            "        [[ 1.2068,  0.9472,  1.6964],\n",
                            "         [ 7.6235,  1.2204,  0.2621],\n",
                            "         [ 0.3200,  1.7626,  1.8560]],\n",
                            "\n",
                            "        [[ 1.6478,  1.5325,  0.6460],\n",
                            "         [ 0.4114,  4.9742,  0.3559],\n",
                            "         [ 3.2568,  0.8296,  1.7869]]])"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "torch.div(torch.rand(3,3,3),torch.rand(3,3,3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "for item in list(np.unique(data_dict['t_te'])):\n",
                "    if item not in list(np.unique(data_dict['t'])):\n",
                "        print('no')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "0.0 in list(np.unique(data_dict['t']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "0e2c091a91198da3c83fa5f5fdee90d73e538d52511d9a8da7d554d565cda77a"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit ('pytorch_gpu': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
