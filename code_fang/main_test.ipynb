{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import scipy\n",
                "import pandas\n",
                "import torch\n",
                "import utils\n",
                "from utils import generate_state_space_Matern_23\n",
                "from scipy import linalg\n",
                "from utils import build_id_key_table\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_file = '../processed_data/beijing_15k.npy'\n",
                "full_data = np.load(data_file, allow_pickle=True).item()\n",
                "\n",
                "fold=0\n",
                "\n",
                "# here should add one more data-loader class\n",
                "data_dict = full_data['data'][fold]\n",
                "data_dict['ndims'] = full_data['ndims']\n",
                "data_dict['num_node'] = full_data['num_node']\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "hyper_dict={}\n",
                "hyper_dict['ls'] = 0.5\n",
                "hyper_dict['var'] = 0.1\n",
                "hyper_dict['device'] = torch.device(\"cpu\")\n",
                "hyper_dict['R_U'] = 5 # dim of each node embedding\n",
                "hyper_dict['c'] = 1.0 # diffusion rate\n",
                "\n",
                "F,P_inf = utils.generate_state_space_Matern_23(data_dict,hyper_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "tr_uni_T_id = np.unique(data_dict['tr_T_disct'])\n",
                "time_data_table = utils.build_time_data_table(data_dict['tr_T_disct'])\n",
                "\n",
                "eind_T = time_data_table[0]\n",
                "\n",
                "ind_T = data_dict['tr_ind'][eind_T]\n",
                "y_T = data_dict['tr_y'][eind_T]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "9"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(y_T)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "a = torch.rand(2,3)\n",
                "b = torch.cat([a,a])\n",
                "b.requires_grad=True "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[0.4252, 0.3326, 0.0931],\n",
                            "        [0.1136, 0.0559, 0.2946],\n",
                            "        [0.4252, 0.3326, 0.0931],\n",
                            "        [0.1136, 0.0559, 0.2946]], requires_grad=True)"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "b"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# all_para = torch.rand(6, requires_grad=True)\n",
                "all_para = torch.rand(6, requires_grad=True)\n",
                "samples = torch.rand(2)\n",
                "\n",
                "class my():\n",
                "    def __init__(self):\n",
                "        self.a = 0\n",
                "\n",
                "    def f(self,all_para):\n",
                "        mu = all_para[0:2] #torch.ones((2,), requires_grad=True)\n",
                "        sigma = all_para[2:4]\n",
                "        # samples = all_para[4:6]    \n",
                "        dist = torch.distributions.multivariate_normal.MultivariateNormal(mu, torch.diag(sigma))\n",
                "        # samples = dist.sample((num_samples,))\n",
                "        logprobs = dist.log_prob(samples)\n",
                "        return logprobs\n",
                "\n",
                "model = my()\n",
                "grads = torch.autograd.functional.jacobian(model.f, all_para)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor(-3.3147, grad_fn=<MulBackward0>)"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "k = model.f( all_para)\n",
                "a = k.detach()\n",
                "s = k*2\n",
                "s"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[0.1580, 0.1014],\n",
                            "        [0.1248, 0.3187]])"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = torch.rand(2,2)\n",
                "a"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([2.2724, 1.3654, 1.5202])"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = torch.rand(3,4)\n",
                "a.sum(-1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor(-1.8105, grad_fn=<SubBackward0>)"
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dist = torch.distributions.multivariate_normal.MultivariateNormal(mu, torch.diag(sigma))\n",
                "logprobs = dist.log_prob(samples)\n",
                "logprobs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# data process:\n",
                "\n",
                "class Bayes_diffu_tensor():\n",
                "    def __init__(self,data_dict,hyper_dict):\n",
                "\n",
                "\n",
                "        # hyper-paras\n",
                "        self.epoch = hyper_dict['epoch'] # passing epoch\n",
                "        self.R_U = hyper_dict['R_U'] # rank of latent factor of embedding\n",
                "        self.device = hyper_dict['device']\n",
                "        \n",
                "        self.a0 = hyper_dict['a0']\n",
                "        self.b0 = hyper_dict['b0']\n",
                "        \n",
                "        \n",
                "\n",
                "        # data-dependent paras\n",
                "        self.data_dict = data_dict\n",
                "        \n",
                "        self.ind_tr = data_dict['ind_tr']\n",
                "        self.y_tr = data_dict['y_tr'].to(self.device) # N*1\n",
                "        self.N = len(data_dict['y_tr'])\n",
                "        self.ndims = data_dict['ndims']\n",
                "        self.num_nodes = sum(self.ndims)\n",
                "        \n",
                "        self.train_time_ind =data_dict['tr_T_disct'] # N*1\n",
                "        self.test_time_ind = data_dict['te_T_disct'] # N*1\n",
                "        \n",
                "        self.time_uni = data_dict['time_uni'] # N_time*1\n",
                "        self.N_time = data_dict['N_time']  \n",
                "        \n",
                "        self.time_id_table = data_dict['time_id_table']\n",
                "        self.F = data_dict['F'].to(self.device) # transition matrix\n",
                "        self.P_inf = data_dict['P_inf'].to(self.device) # stationary covar\n",
                "        \n",
                "    \n",
                "            \n",
                "        # init the message factor of llk term (U_llk, tau)\n",
                "        # and transition term (U_f: U_forard, U_b: U_backward)\n",
                "        \n",
                "        # actually, it's the massage from llk-factor -> variabel U\n",
                "        # for here, we arrange the U-msg in mode-node way for efficient indexing in LLK\n",
                "        self.msg_U_llk_m = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_U_llk_v = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_tau_a = torch.ones(self.N_time,1).to(self.device)\n",
                "        self.msg_tau_b = torch.ones(self.N_time,1).to(self.device)\n",
                "        \n",
                "        # actually, it's the massage from transition-factor -> variabel U\n",
                "        # for here, we arrange the U-msg in concat-all way for efficient computing in transition\n",
                "        self.msg_U_f_m = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_f_v = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        \n",
                "        self.msg_U_b_m = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_b_v = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time \n",
                "\n",
                "\n",
                "    \n",
                "        # init the calibrating factors / q_del in draft\n",
                "        \n",
                "        # actually, it's the massage from variabel U -> llk-factor\n",
                "        self.msg_U_llk_m_del = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.msg_U_llk_v_del = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        # as the computing of msg_tau_del is trival, we don't assign extra varb gor it  \n",
                "        \n",
                "        # actually, it's the massage from variabel U -> trans-factor\n",
                "        self.msg_U_f_m_del = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_f_v_del = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        \n",
                "        self.msg_U_b_m_del = [torch.rand(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time\n",
                "        self.msg_U_b_v_del = [torch.ones(self.num_nodes,self.R_U).double().to(self.device)] * self.N_time \n",
                "        \n",
                "    \n",
                "        # init the post. U\n",
                "        \n",
                "        self.post_U_m = [[torch.rand(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        self.post_U_v = [[torch.ones(ndim,self.R_U).double().to(self.device) \\\n",
                "            for ndim in self.ndims] ] * self.N_time\n",
                "        \n",
                "        # uid-data table \n",
                "        self.uid_table, self.data_table = build_id_key_table(self.nmod,self.ind_tr) \n",
                "        \n",
                "\n",
                "def msg_update_U_llk(self,T):\n",
                "    pass\n",
                "    \n",
                "def msg_update_U_trans(self,T,mode='forward'):\n",
                "    pass\n",
                "\n",
                "def msg_update_tau(self,T):\n",
                "    pass\n",
                "\n",
                "def msg_update_U_llk_del(self,T):\n",
                "    pass\n",
                "    \n",
                "def msg_update_U_trans_del(self,T):\n",
                "    pass\n",
                "\n",
                "def post_update_U(self,T):\n",
                "    pass\n",
                "    \n",
                "def post_update_tau(self):\n",
                "    pass\n",
                "    \n",
                "        \n",
                "        \n",
                "        \n",
                "        \n",
                "        \n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "F,P_inf = utils.generate_state_space_Matern_23(data_dict,hyper_dict,fold)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([5, 3, 3])"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = [torch.rand(3,3,3),torch.rand(2,3,3)]\n",
                "torch.cat(a,0).shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[[ 0.2385,  0.8594, 14.5998],\n",
                            "         [ 0.8539,  0.3681,  1.2468],\n",
                            "         [ 3.4039,  0.8496,  2.9541]],\n",
                            "\n",
                            "        [[ 1.2068,  0.9472,  1.6964],\n",
                            "         [ 7.6235,  1.2204,  0.2621],\n",
                            "         [ 0.3200,  1.7626,  1.8560]],\n",
                            "\n",
                            "        [[ 1.6478,  1.5325,  0.6460],\n",
                            "         [ 0.4114,  4.9742,  0.3559],\n",
                            "         [ 3.2568,  0.8296,  1.7869]]])"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "torch.div(torch.rand(3,3,3),torch.rand(3,3,3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "for item in list(np.unique(data_dict['t_te'])):\n",
                "    if item not in list(np.unique(data_dict['t'])):\n",
                "        print('no')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "0.0 in list(np.unique(data_dict['t']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "0e2c091a91198da3c83fa5f5fdee90d73e538d52511d9a8da7d554d565cda77a"
        },
        "kernelspec": {
            "display_name": "Python 3.9.6 64-bit ('pytorch_gpu': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
